{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задачи классификации и логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В машинном обучении задачей классификации называется ситуация, когда в качестве $y$ (переменной которую мы хотим предсказать) выступает категориальная переменная. Это означает, что данная переменная задает разбиение нашего датасета на классы, которых может быть как 2, так и больше. Нашей задачей в таком случае становится построение алгоритма, который бы смог отделить классы друг от друга в пространстве признаков, или что тоже самое провести разделяющую поверхность между классами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде чем что-то обучать, нам необходимо выбрать функцию потерь для нашей задачи. Одним из решений является логистическая функция потерь, которая имееть следующий вид:\n",
    "\n",
    "$$\n",
    "L(y, z) = -\\sum_i y_i \\log(z_i) + (1 - y_i) \\log(1 - z_i)\n",
    "$$\n",
    "\n",
    "где $z_i$ - это вероятность принадлежности к классу 1 предсказанная нашим алгоритмом. *Помедетируйте над лоссом! Подумайте почему правильно предсказанная вероятность минимизирует его!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы заставить ваш алгоритм возвращать значения из отрезка $[0, 1]$, вы можете обернуть его выход в сигмоиду. Сигмоида это любая S - образная функция принимающая значения из отрезка $[0, 1]$. Частный случай: логистическая функция, имеет следующий вид:\n",
    "\n",
    "$$\n",
    "\\sigma (x) = \\frac{1}{1 + e^{-x}}\n",
    "$$\n",
    "\n",
    "Посмотрим как она выглядит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f8f9cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "x = np.linspace(-10, 10, 1000)\n",
    "\n",
    "def logistic_function(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "plt.title('Logit - function')\n",
    "plt.plot(x, sigmoida(x))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы видите, в целом, вы можете запихнуть в такую функцию что угодно, и получите некоторую оценку вероятности. Все что вам нужно, это чтобы ваш алгоритм был дифференцируемый.\n",
    "\n",
    "### Multi-class classification\n",
    "\n",
    "Еще один момент, который нужно уточнить, это что делать в случае, когда классов много. В этом случае мы можем использовать обобщение логистической функции потерь, на несколько классов. Такой лосс называется \"кросс-энтропия\" и имееть следующий вид\n",
    "\n",
    "$$\n",
    "L(y, z) = -\\sum_i \\log(z_{y_i})\n",
    "$$\n",
    "\n",
    "Здесь $z_{y_i}$ - это вероятность, которую предсказал ваш алгоритм для истинного класса $y_i$. Теперь мы можем сделать что-то ручками."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках семинара мы будем работать с датасетом ирисы Фишера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data['data']\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание.** \n",
    "Нарисуйте первый и третий признак на диаграмме и подсветите различные классы. Что можно сказат? Вы бы смогли построить правила по которым можно отличить один класс от другого?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем обучить модель, которая бы смогла отличать два класса. Давайте мы поместим линейную регрессию внутрь сигмоиды? Получится алгоритм следующего вида\n",
    "\n",
    "$$\n",
    "a(x, w) = \\frac{1}{1 + e^{-x^T w - b}}\n",
    "$$\n",
    "\n",
    "Такая модель называется *логит-регрессия*. Возьмем ее из пакета sklearn и обучим отделять друг от друга два класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание.** Создайте новый датасет в котором оставьте только объекты 0 и 1 класса, в качестве признака возьмите ширину лепестка (4-й столбец). Разбейте выборку на `train` и `test` с помощью функции `train_test_split` в соотношении 4 к 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание.** Обучите логит-регрессию. *Вспоминайте стандартный интерфейс `sklearn`!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание.** Нарисуйте на одномерной прямой вероятность принадлежности к классу 1 в зависимости от ширины лепестка используя функцию `visualize_one_dimensional_logit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_one_dimensional_logit(logit_regression, X, y):\n",
    "    assert(len(set(y)) == 2)\n",
    "    assert(X.shape[1] == 1)\n",
    "    \n",
    "    X_new = np.linspace(0, 3, 1000).reshape(-1, 1)\n",
    "    y_proba = logit_regression.predict_proba(X_new)\n",
    "    decision_boundary = X_new[y_proba[:, 1] >= 0.5][0]\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(X[y==0], y[y==0], \"bs\")\n",
    "    plt.plot(X[y==1], y[y==1], \"g^\")\n",
    "    plt.plot([decision_boundary, decision_boundary], [-1, 2], \"k:\", linewidth=2)\n",
    "    plt.plot(X_new, y_proba[:, 1], \"g-\", linewidth=2, label=\"Iris-Setosa\")\n",
    "    plt.plot(X_new, y_proba[:, 0], \"b--\", linewidth=2, label=\"Iris-Versicolor\")\n",
    "    plt.text(decision_boundary+0.02, 0.15, \"Decision  boundary\", fontsize=14, color=\"k\", ha=\"center\")\n",
    "    plt.arrow(decision_boundary, 0.08, -0.3, 0, head_width=0.05, head_length=0.1, fc='b', ec='b')\n",
    "    plt.arrow(decision_boundary, 0.92, 0.3, 0, head_width=0.05, head_length=0.1, fc='g', ec='g')\n",
    "    plt.xlabel(\"Petal width (cm)\", fontsize=14)\n",
    "    plt.ylabel(\"Probability\", fontsize=14)\n",
    "    plt.legend(loc=\"center left\", fontsize=14)\n",
    "    plt.axis([0, 3, -0.02, 1.02])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь обучим модель, чтобы отделить сорт Virginica от двух других."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Задание. ** Сформируйте датасет с двумя признаками (ширина и длина лепестка), где вашим `target` будет 1, если цветок сорта Virginica  и 0, если нет. Обучите логит регрессию на таком датасете без регуляризации (каким для этого нужно сделать параметр $C$?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Задание. ** Визуализируйте разделяющую прямую с функцией `visualize_two_dimensional_logit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_two_dimensional_logit(logit_regression, X, y):\n",
    "    x0, x1 = np.meshgrid(\n",
    "        np.linspace(2.9, 7, 500).reshape(-1, 1),\n",
    "        np.linspace(0.8, 2.7, 200).reshape(-1, 1),\n",
    "    )\n",
    "    X_new = np.c_[x0.ravel(), x1.ravel()]\n",
    "\n",
    "    y_proba = logit_regression.predict_proba(X_new)\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(X[y==0, 0], X[y==0, 1], \"bs\")\n",
    "    plt.plot(X[y==1, 0], X[y==1, 1], \"g^\")\n",
    "\n",
    "    zz = y_proba[:, 1].reshape(x0.shape)\n",
    "    contour = plt.contour(x0, x1, zz, cmap=plt.cm.brg)\n",
    "\n",
    "\n",
    "    left_right = np.array([2.9, 7])\n",
    "    boundary = -(logit_regression.coef_[0][0] * left_right + logit_regression.intercept_[0]) / logit_regression.coef_[0][1]\n",
    "\n",
    "    plt.clabel(contour, inline=1, fontsize=12)\n",
    "    plt.plot(left_right, boundary, \"k--\", linewidth=3)\n",
    "    plt.text(3.5, 1.5, \"Not Iris-Virginica\", fontsize=14, color=\"b\", ha=\"center\")\n",
    "    plt.text(6.5, 2.3, \"Iris-Virginica\", fontsize=14, color=\"g\", ha=\"center\")\n",
    "    plt.xlabel(\"Petal length\", fontsize=14)\n",
    "    plt.ylabel(\"Petal width\", fontsize=14)\n",
    "    plt.axis([2.9, 7, 0.8, 2.7])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Задание. **\n",
    "Обучите модель на всех данных (классифицируем Virginica против всех остальных)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще немного терминологии. После того как мы сделали предсказание, мы можем посчитать следующие величины:\n",
    "\n",
    "* TP (True Positive): количество правильно предсказанных объектов класса 1.\n",
    "* TN (True Negative): количество правильно предсказанных объектов класса 0.\n",
    "* FP (False Positive): количество объектов класса 0, которые мы классифицировали неправильно.\n",
    "* FN (False Negative): количество объектов класса 1, которые мы классифицировали неправильно.\n",
    "\n",
    "Заметим, что логит-регрессия возвращает вероятности, а значит нам нужно выбрать границу, выше которой мы будем считать, что объекты принадлежат классу 1, а ниже классу 0 (на графиках выше это граница равно 0.5).\n",
    "\n",
    "По разному выбирая такую границу, мы можем получить целый набор точек TP и FP. Посчитав долю (а не количество) и расположив их на прямой, можно получить кривую называемую ROC кривой.\n",
    "\n",
    "Чтобы оценить качество модель, как и в задачах регрессии, в задачах классификации используются метрики качества.\n",
    "\n",
    " * Accuracy: доля правильных ответов.\n",
    " * ROC-AUC (Area Under Curve): площадь под ROC кривой.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Задание. ** Оцените accuracy вашего классификатора на train и test. Постройте roc кривую. Посчитайте ROC-AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Задание. Бонус. ** Теперь построим модель, которая бы могла отделять все три класса. Одним из подходов является построение модели для каждого класса, которая могла бы отделять этот класс от всех остальных. После этого мы смотрим на предсказанные вероятности и в качестве нашего предсказания выбираем тот класс, где вероятности наибольшая. Реализуйте такую процедуру. Визуализируйте разбиение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
